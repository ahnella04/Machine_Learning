{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "#from arena_util import write_json\n",
    "#from arena_util import remove_seen\n",
    "#from arena_util import is_tag\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from collections import Counter\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "import io\n",
    "import numpy as np\n",
    "import distutils.dir_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(data, FILE_PATH, fname):\n",
    "    def _conv(o):\n",
    "        if isinstance(o, (np.int64, np.int32)):\n",
    "            return int(o)\n",
    "        raise TypeError\n",
    "\n",
    "    parent = os.path.dirname(fname)\n",
    "    distutils.dir_util.mkpath(FILE_PATH + parent)\n",
    "    with io.open(FILE_PATH + fname, \"w\", encoding=\"utf-8\") as f:\n",
    "        json_str = json.dumps(data, ensure_ascii=False, default=_conv)\n",
    "        f.write(json_str)\n",
    "\n",
    "def remove_seen(seen, l):\n",
    "    seen = set(seen)\n",
    "    return [x for x in l if not (x in seen)]\n",
    "\n",
    "###########arena_util 클래스에 아래 함수들 추가! ##########    \n",
    "def is_tag(word,tags_list_all):\n",
    "    if word in tags_list_all :\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def before_updt_date(cand_song_idx,updt_date,song_meta):\n",
    "            \n",
    "    updt_date = int(re.sub('-','',updt_date)[:8])\n",
    "    return_idx = []\n",
    "    \n",
    "    for i in cand_song_idx:\n",
    "        if int(song_meta.loc[i,'issue_date'])>updt_date :\n",
    "            continue\n",
    "        else:\n",
    "            return_idx.append(i)\n",
    "\n",
    "    return return_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_addtags.json , val_addtags.json 읽어왔으면 실행안해도 됌!!\n",
    "\n",
    "class MakeAdditionalTags:\n",
    "    def __init__(self,FILE_PATH):\n",
    "        self.FILE_PATH = FILE_PATH\n",
    "        with open(os.path.join(FILE_PATH, 'genre_gn_all.json'), encoding=\"utf-8\") as f:\n",
    "            self.genre_gn_all = json.load(f)\n",
    "        self.res = []\n",
    "            \n",
    "\n",
    "    def mk_genre_tags (self,songs_input,song_meta, genre_gn_all, tag_num):\n",
    "        genre_list=[]\n",
    "        genre_tags_list=[]\n",
    "        \n",
    "        for i in songs_input:\n",
    "            genre_list+=song_meta.loc[i,'song_gn_gnr_basket']\n",
    "        c = Counter(genre_list)\n",
    "        genre_list=c.most_common(tag_num)\n",
    "        \n",
    "        for i in range(len(genre_list)):\n",
    "            try:genre_names = self.genre_gn_all[genre_list[i][0]].split('/')\n",
    "            except KeyError : continue\n",
    "            genre_tags_list += genre_names\n",
    "            \n",
    "        return genre_tags_list\n",
    "    \n",
    "    def sentence_piece (self,train):\n",
    "        titles_train = train[train['plylst_title'] != '']['plylst_title']\n",
    "\n",
    "        f = open('titles.txt', mode='wt', encoding='utf-8')\n",
    "        for i in titles_train : \n",
    "            f.write(re.sub(r'[^가-힣a-zA-Z0-9\\s]','',i)+'\\n')\n",
    "\n",
    "        for tags in train['tags']:\n",
    "            for tag in tags:\n",
    "                f.write(tag)\n",
    "                f.write(' ')\n",
    "            f.write('\\n')\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        templates = '--input=titles.txt \\\n",
    "        --model_prefix=train \\\n",
    "        --vocab_size=20000 \\\n",
    "        --character_coverage=1.0 \\\n",
    "        --model_type=bpe \\\n",
    "        '\n",
    "\n",
    "        spm.SentencePieceTrainer.Train(templates)\n",
    "    \n",
    "    def mk_title_tags (self,data,tag_list_all):\n",
    "        sp = spm.SentencePieceProcessor()\n",
    "        sp.load('train.model')\n",
    "\n",
    "        sp_title = []\n",
    "        for i in tqdm(data['plylst_title']) :\n",
    "            i = re.sub(r'[^가-힣a-zA-Z0-9\\s]','',i)\n",
    "            if type(i) != str : sp_title.append([])\n",
    "            else:\n",
    "                pieces = sp.encode_as_pieces(i)\n",
    "                plus_tag = []\n",
    "                for i in pieces:\n",
    "                    tag = re.sub('▁','',i)\n",
    "\n",
    "                    if (len(tag) > 1) and (tag[-1] == '과' or tag[-1] == '와'):\n",
    "                        tag = tag[:-1]\n",
    "\n",
    "                    if is_tag(tag,tag_list_all):\n",
    "                        plus_tag.append(tag)\n",
    "                sp_title.append(plus_tag)\n",
    "\n",
    "        data['title_tags'] = sp_title\n",
    "    \n",
    "    def run (self,data,fname):\n",
    "        data['genre_tags'] = data.apply(lambda x : self.mk_genre_tags(x['songs'],song_meta,self.genre_gn_all,2),axis=1)\n",
    "        tags_list_all = []\n",
    "        for tags in train['tags']:\n",
    "            tags_list_all+=tags\n",
    "        for tags in val['tags']:\n",
    "            tags_list_all+=tags\n",
    "        tags_list_all = list(set(tags_list_all))\n",
    "        \n",
    "        self.mk_title_tags(data,tags_list_all)\n",
    "        \n",
    "\n",
    "        #태그 추가한 val.json 데이터 새로 쓰기\n",
    "        for pid in data.index:\n",
    "            self.res.append({\n",
    "                        \"tags\":data.loc[pid,\"tags\"],\n",
    "                        \"id\": data.loc[pid, \"id\"],\n",
    "                        \"songs\": data.loc[pid, \"songs\"],\n",
    "                        \"plylst_title\": data.loc[pid, \"plylst_title\"],\n",
    "                        \"like_cnt\": data.loc[pid, \"like_cnt\"],\n",
    "                        \"updt_date\": data.loc[pid, \"updt_date\"],\n",
    "                        \"genre_tags\": data.loc[pid, \"genre_tags\"],\n",
    "                        \"title_tags\": data.loc[pid, \"title_tags\"]\n",
    "                })\n",
    "\n",
    "        write_json(self.res, self.FILE_PATH, fname+'_addtags.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10740/10740 [00:06<00:00, 1673.50it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "FILE_PATH = ''\n",
    "val_tags = MakeAdditionalTags(FILE_PATH)\n",
    "val_tags.run(val,'val')\n",
    "train_tags = MakeAdditionalTags(FILE_PATH)\n",
    "train_tags.run(train,'train')\n",
    "'''\n",
    "val = pd.read_json('val.json',typ = 'frame',encoding='utf8')\n",
    "\n",
    "train = pd.read_json('train.json',typ = 'frame',encoding='utf8')\n",
    "song_meta = pd.read_json('song_meta.json',typ = 'frame',encoding='utf8')\n",
    "test = pd.read_json('test.json',typ='frame',encoding='utf8')\n",
    "test_tags = MakeAdditionalTags(FILE_PATH)\n",
    "test_tags.run(test,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from arena_util import before_updt_date\n",
    "#from AreanaUtil import remove_seen\n",
    "\n",
    "class MakeBaselineResults:\n",
    "    \n",
    "    def __init__(self, FILE_PATH):\n",
    "        self.FILE_PATH = FILE_PATH\n",
    "        \n",
    "        with open(os.path.join(FILE_PATH, 'train_addtags.json'), encoding=\"utf-8\") as f:\n",
    "            self.train = pd.DataFrame(json.load(f))\n",
    "        \n",
    "        with open(os.path.join(FILE_PATH, 'val_addtags.json'), encoding=\"utf-8\") as f:\n",
    "            self.val = pd.DataFrame(json.load(f))\n",
    "          \n",
    "        with open(os.path.join(FILE_PATH, 'test_addtags.json'), encoding=\"utf-8\") as f:\n",
    "            self.test = pd.DataFrame(json.load(f))\n",
    "        \n",
    "        with open(os.path.join(FILE_PATH, 'song_meta.json'), encoding=\"utf-8\") as f:\n",
    "            self.song_meta = pd.DataFrame(json.load(f))\n",
    "        \n",
    "        \n",
    "    \n",
    "    def intersect_cnt(self,tags,cand_tags,title_tags,genre_tags):\n",
    "        \n",
    "        tags_o = len(list(set(tags)&set(cand_tags))) * 3\n",
    "        tags_t = len(list(set(tags)&set(title_tags))) * 2\n",
    "        tags_g = len(list(set(tags)&set(genre_tags)))\n",
    "\n",
    "        score = tags_o+tags_t+tags_g\n",
    "\n",
    "        return score\n",
    "\n",
    "    def mk_rec(self, x):\n",
    "        t = pd.concat([self.train, self.val,self.test], ignore_index = True)\n",
    "        t['cnt'] = 0\n",
    "\n",
    "        tags_input = x.tags.copy()\n",
    "        tags_genre = x.genre_tags.copy()\n",
    "        tags_title = x.title_tags.copy()\n",
    "\n",
    "        tag_score = t['tags'].apply(lambda x : self.intersect_cnt(x,tags_input,tags_title,tags_genre))\n",
    "        t['cnt'] += tag_score\n",
    "\n",
    "\n",
    "        t = t.sort_values(by='cnt',ascending=False)\n",
    "\n",
    "        max_cnt = t.cnt.values[0]\n",
    "\n",
    "        tag_result = []\n",
    "        song_result = []\n",
    "\n",
    "        while max_cnt > 0  :\n",
    "\n",
    "            tl = list(t[t['cnt'] == max_cnt]['tags'])\n",
    "            sl = list(t[t['cnt'] == max_cnt]['songs']) \n",
    "\n",
    "            tc=Counter([item for sublist in tl for item in sublist]).most_common()\n",
    "            sc=Counter([item for sublist in sl for item in sublist]).most_common()\n",
    "            \n",
    "            #before updt_date인지 체크\n",
    "            cand_song = list(map(lambda x : x[0], sc))\n",
    "            song_result += before_updt_date(cand_song,x.updt_date,self.song_meta)\n",
    "\n",
    "            for i in tc:\n",
    "                if (i[0] not in x['tags']) & (i[0] not in tag_result):\n",
    "                    tag_result.append(i[0])\n",
    "            \n",
    "            song_result = remove_seen(x.songs, song_result)\n",
    "            \n",
    "            if ((len(song_result) >= 100) & (len(tag_result) >= 10)) :\n",
    "                break\n",
    "\n",
    "            max_cnt -= 1\n",
    "\n",
    "        return [tag_result[:10],song_result[:100]]\n",
    "\n",
    "    def run(self):\n",
    "        tqdm.pandas()\n",
    "        \n",
    "        #song 개수가 3개 미만일 경우만 rec_songs, rec_tags 뽑아내기\n",
    "        #최종 제출할 때는 val -> test로\n",
    "        \n",
    "        val_not = self.test[(self.test.songs.str.len() >= 3)].copy()\n",
    "        blank = []\n",
    "        for i in range(len(val_not)):\n",
    "            blank.append([])\n",
    "        val_not['rec_songs'] = blank\n",
    "        val_not['rec_tags'] = blank\n",
    "        \n",
    "        val_min = self.test[(self.test.songs.str.len() < 3)].copy()\n",
    "        val_min['rec'] = val_min.progress_apply(lambda x : self.mk_rec(x), axis = 1)\n",
    "        val_min['rec_tags'] = val_min.apply(lambda x : x.rec[0] ,axis = 1)\n",
    "        val_min['rec_songs'] = val_min.apply(lambda x : x.rec[1] ,axis = 1)\n",
    "        val_min = val_min.drop(columns = 'rec')\n",
    "        \n",
    "        self.test = pd.concat([val_not, val_min]).sort_index(ascending=True)\n",
    "        \n",
    "        self.res = []\n",
    "        \n",
    "        for pid in self.test.index:\n",
    "            self.res.append({\n",
    "                    \"id\": self.test.loc[pid, \"id\"],\n",
    "                    \"songs\": self.test.loc[pid, \"rec_songs\"],\n",
    "                    \"tags\": self.test.loc[pid, \"rec_tags\"]\n",
    "            })\n",
    "        \n",
    "        write_json(self.res, self.FILE_PATH, \"base_results.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahrimahn/opt/anaconda3/lib/python3.7/site-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      " 99%|█████████▊| 2077/2104 [30:54<00:26,  1.01it/s]  "
     ]
    }
   ],
   "source": [
    "FILE_PATH = '/Users/ahrimahn/melon music/kakao arena/'\n",
    "base = MakeBaselineResults(FILE_PATH)\n",
    "results = base.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaylistEmbedding:\n",
    "    def __init__(self, FILE_PATH):\n",
    "        self.FILE_PATH = FILE_PATH\n",
    "        self.min_count = 3\n",
    "        self.size = 100\n",
    "        self.window = 210 #원래 값 210\n",
    "        self.sg = 5\n",
    "        \n",
    "        self.p2v_model = WordEmbeddingsKeyedVectors(self.size)\n",
    "        #self.p2v_model = KeyedVectors.load(\"p2v_model.model\")\n",
    "        #self.w2v_model = Word2Vec.load(\"word2vec.model\")\n",
    "        \n",
    "        with open(os.path.join(FILE_PATH, 'train.json'), encoding=\"utf-8\") as f:\n",
    "            self.train = json.load(f)\n",
    "        \n",
    "        with open(os.path.join(FILE_PATH, 'val.json'), encoding=\"utf-8\") as f:\n",
    "            self.val = json.load(f)\n",
    "            \n",
    "        with open(os.path.join(FILE_PATH, 'test.json'), encoding=\"utf-8\") as f:\n",
    "            self.test = json.load(f)\n",
    "        \n",
    "        with open(os.path.join(FILE_PATH, 'song_meta.json'), encoding=\"utf-8\") as f:\n",
    "            self.song_meta = pd.DataFrame(json.load(f))\n",
    "        \n",
    "        with open(os.path.join(FILE_PATH, 'base_results.json'), encoding=\"utf-8\") as f: #baseline results\n",
    "            self.most_results = json.load(f)\n",
    "        \n",
    "    def get_dic(self, train, val, test):\n",
    "        song_dic = {}\n",
    "        tag_dic = {}\n",
    "        \n",
    "        train = train + val\n",
    "        data = train + test\n",
    "        \n",
    "        for q in tqdm(data):\n",
    "            song_dic[str(q['id'])] = q['songs']\n",
    "            tag_dic[str(q['id'])] = q['tags']\n",
    "\n",
    "        \n",
    "        self.song_dic = song_dic\n",
    "        self.tag_dic = tag_dic\n",
    "        total = list(map(lambda x: list(map(str, x['songs'])) + list(x['tags']), data))\n",
    "        total = [x for x in total if len(x)>1]\n",
    "        self.total = total\n",
    "        \n",
    "        \n",
    "    def get_w2v(self, total, min_count, size, window, sg):\n",
    "        w2v_model = Word2Vec(total, min_count = min_count, size = size, window = window, sg = sg, workers = 4)\n",
    "        self.w2v_model = w2v_model\n",
    "        w2v_model.save(\"word2vec.model\")\n",
    "    \n",
    "\n",
    "    def update_p2v(self, train, val, test, w2v_model):\n",
    "        ID = []   \n",
    "        vec = []\n",
    "        for q in tqdm(train + val + test):\n",
    "            tmp_vec = 0\n",
    "            \n",
    "            #add_tags를 train에는 안넣고 추천 때만 넣는다??\n",
    "            songs_and_tags = q['songs'] + q['tags']\n",
    "            \n",
    "            \n",
    "            if len(songs_and_tags)>=1:\n",
    "                for song in songs_and_tags:\n",
    "                    try:\n",
    "                        tmp_vec += w2v_model.wv.get_vector(str(song))\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "            if type(tmp_vec)!=int:\n",
    "                ID.append(str(q['id']))\n",
    "                vec.append(tmp_vec)\n",
    "        self.p2v_model.add(ID, vec)\n",
    "        self.p2v_model.save('p2v_model.model')\n",
    "    \n",
    "    def popular_results (self,train) :\n",
    "        tags_dict = {}\n",
    "        songs_dict = {}\n",
    "        \n",
    "        for i in tqdm(train):\n",
    "            for j in i['tags']:\n",
    "                if j in tags_dict:\n",
    "                    tags_dict[j]+= 1\n",
    "                else:\n",
    "                    tags_dict[j] = 1\n",
    "            for j in i['songs']:\n",
    "                if j in songs_dict:\n",
    "                    songs_dict[j] += 1\n",
    "                else:\n",
    "                    songs_dict[j] = 1\n",
    "\n",
    "        self.popular_tags = list(map(lambda x: x[0],sorted(tags_dict.items(), reverse=True,key=lambda item: item[1])[:10]))\n",
    "        self.popular_songs = list(map(lambda x: x[0],sorted(songs_dict.items(), reverse=True,key=lambda item: item[1])[:100]))\n",
    "    \n",
    "    def get_result(self, p2v_model, song_dic, tag_dic, most_results, val):\n",
    "        answers = []\n",
    "\n",
    "        for n, q in tqdm(enumerate(val), total = len(val)):\n",
    "            try:\n",
    "                cand_id = [x[0] for x in p2v_model.most_similar(str(q['id']), topn=200)]\n",
    "                \n",
    "                #similarity 기준치 이상인 플레이리스트로만!\n",
    "                \n",
    "                #similarity 가 1에 가까운 플레이리스트는 모든 노래를 추천??!\n",
    "                \n",
    "                get_song = []\n",
    "                get_tag = []\n",
    "                cand_song = []\n",
    "                \n",
    "                for ID in cand_id:\n",
    "                    get_song += song_dic[ID]\n",
    "                    get_tag += tag_dic[ID]\n",
    "                \n",
    "                cand_song += list(pd.value_counts(get_song)[:1000].index)    \n",
    "                \n",
    "                get_song = before_updt_date(cand_song,q['updt_date'],self.song_meta) #before_updt_date 모듈 추가!\n",
    "                \n",
    "                get_tag = list(pd.value_counts(get_tag)[:10].index)\n",
    "                \n",
    "                answers.append({\n",
    "                    \"id\": q[\"id\"],\n",
    "                    \"songs\": remove_seen(q[\"songs\"], get_song)[:100],\n",
    "                    \"tags\": remove_seen(q[\"tags\"], get_tag)[:10],\n",
    "                })\n",
    "                \n",
    "            except: #키에러가 나는 이유는?! \n",
    "                answers.append({\n",
    "                  \"id\": most_results[n][\"id\"],\n",
    "                  \"songs\": most_results[n]['songs'],\n",
    "                  \"tags\": most_results[n][\"tags\"],\n",
    "                })\n",
    "\n",
    "        # check and update answer\n",
    "        \n",
    "        for n, q in enumerate(answers):\n",
    "            if len(q['songs'])!=100:\n",
    "                answers[n]['songs'] += remove_seen(q['songs'], self.most_results[n]['songs'])[:100-len(q['songs'])]\n",
    "            \n",
    "            if len(q['tags'])!=10:\n",
    "                answers[n]['tags'] += remove_seen(q['tags'], self.most_results[n]['tags'])[:10-len(q['tags'])]\n",
    "            \n",
    "        self.answers = answers\n",
    "    \n",
    "    def run(self):\n",
    "        self.get_dic(self.train, self.val, self.test)\n",
    "        self.get_w2v(self.total, self.min_count, self.size, self.window, self.sg)\n",
    "        self.update_p2v(self.train, self.val, self.test, self.w2v_model)\n",
    "        self.get_result(self.p2v_model, self.song_dic, self.tag_dic, self.most_results, self.test)\n",
    "        \n",
    "        write_json(self.answers,self.FILE_PATH, 'results.json')\n",
    "        return (self.answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148826/148826 [00:00<00:00, 689842.78it/s]\n",
      "100%|██████████| 148826/148826 [00:19<00:00, 7570.64it/s] \n",
      "100%|██████████| 10740/10740 [02:34<00:00, 69.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실행시간 : 1037.623545885086\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "FILE_PATH = '/Users/ahrimahn/melon music/kakao arena/'\n",
    "U_space = PlaylistEmbedding(FILE_PATH)\n",
    "U_space.run()\n",
    "print(\"실행시간 :\",time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['기분전환', '감성', '휴식', '발라드', '잔잔한', '드라이브', '힐링', '사랑', '새벽', '밤'],\n",
       " [144663,\n",
       "  116573,\n",
       "  357367,\n",
       "  366786,\n",
       "  654757,\n",
       "  133143,\n",
       "  349492,\n",
       "  675115,\n",
       "  463173,\n",
       "  42155,\n",
       "  610933,\n",
       "  396828,\n",
       "  461341,\n",
       "  174749,\n",
       "  520093,\n",
       "  701557,\n",
       "  549178,\n",
       "  485155,\n",
       "  650494,\n",
       "  523521,\n",
       "  13281,\n",
       "  648628,\n",
       "  449244,\n",
       "  680366,\n",
       "  169984,\n",
       "  422915,\n",
       "  11657,\n",
       "  418935,\n",
       "  187047,\n",
       "  547967,\n",
       "  422077,\n",
       "  350309,\n",
       "  627363,\n",
       "  625875,\n",
       "  300087,\n",
       "  132994,\n",
       "  215411,\n",
       "  427724,\n",
       "  442014,\n",
       "  668128,\n",
       "  582252,\n",
       "  663256,\n",
       "  253755,\n",
       "  643628,\n",
       "  448116,\n",
       "  339802,\n",
       "  581799,\n",
       "  348200,\n",
       "  26083,\n",
       "  37748,\n",
       "  341513,\n",
       "  505036,\n",
       "  199262,\n",
       "  407828,\n",
       "  105140,\n",
       "  68348,\n",
       "  140867,\n",
       "  235773,\n",
       "  209993,\n",
       "  209135,\n",
       "  339124,\n",
       "  487911,\n",
       "  493762,\n",
       "  672550,\n",
       "  509998,\n",
       "  531820,\n",
       "  27469,\n",
       "  157055,\n",
       "  519391,\n",
       "  473514,\n",
       "  232874,\n",
       "  75842,\n",
       "  117595,\n",
       "  446812,\n",
       "  295250,\n",
       "  152422,\n",
       "  224921,\n",
       "  678762,\n",
       "  351342,\n",
       "  15318,\n",
       "  377243,\n",
       "  146989,\n",
       "  246531,\n",
       "  205179,\n",
       "  645489,\n",
       "  108004,\n",
       "  464051,\n",
       "  13198,\n",
       "  302646,\n",
       "  152475,\n",
       "  343974,\n",
       "  236393,\n",
       "  95323,\n",
       "  640657,\n",
       "  459256,\n",
       "  88503,\n",
       "  362966,\n",
       "  674160,\n",
       "  424813,\n",
       "  154858])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
